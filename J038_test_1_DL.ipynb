{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J038-test-1-DL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPuvRJ3ZuAMsCZh9XIYMWPF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devesh-Patodia/DL-J038/blob/labwork/J038_test_1_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3lbEseKtBSh",
        "colab_type": "code",
        "outputId": "cf4abccd-35d3-4943-fd6a-af0f1ff1ce47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history=model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.2277 - acc: 0.9310 - val_loss: 0.1077 - val_acc: 0.9666\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0843 - acc: 0.9739 - val_loss: 0.0884 - val_acc: 0.9733\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0555 - acc: 0.9830 - val_loss: 0.0714 - val_acc: 0.9791\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0394 - acc: 0.9874 - val_loss: 0.0720 - val_acc: 0.9787\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0284 - acc: 0.9909 - val_loss: 0.0822 - val_acc: 0.9783\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0227 - acc: 0.9925 - val_loss: 0.0865 - val_acc: 0.9806\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0172 - acc: 0.9946 - val_loss: 0.0944 - val_acc: 0.9801\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0145 - acc: 0.9958 - val_loss: 0.0957 - val_acc: 0.9813\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0127 - acc: 0.9962 - val_loss: 0.0982 - val_acc: 0.9819\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0098 - acc: 0.9970 - val_loss: 0.1065 - val_acc: 0.9811\n",
            "Test loss: 0.10652450226062114\n",
            "Test accuracy: 0.9811\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_33 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzxvYfLIxzax",
        "colab_type": "code",
        "outputId": "9158d29c-ea80-4eb0-8e1a-5eb585d7a3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)\n",
        "\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0923 - val_acc: 0.9840\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0904 - val_acc: 0.9838\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0894 - val_acc: 0.9840\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0888 - val_acc: 0.9842\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0882 - val_acc: 0.9840\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0878 - val_acc: 0.9843\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0874 - val_acc: 0.9842\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0871 - val_acc: 0.9844\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0869 - val_acc: 0.9847\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 9.5129e-04 - acc: 0.9998 - val_loss: 0.0866 - val_acc: 0.9847\n",
            "Test loss: 0.08664665951977013\n",
            "Test accuracy: 0.9847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItLp74QwzATf",
        "colab_type": "text"
      },
      "source": [
        "**SGD**\n",
        "\n",
        "Test loss: 0.08664665951977013\n",
        "\n",
        "\n",
        "Test accuracy: 0.9847"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhHi5SE1x3bN",
        "colab_type": "code",
        "outputId": "c2166b73-92e7-4dcc-ef0c-678b25084ec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0104 - acc: 0.9971 - val_loss: 0.0971 - val_acc: 0.9822\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0076 - acc: 0.9977 - val_loss: 0.1102 - val_acc: 0.9815\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0068 - acc: 0.9979 - val_loss: 0.1128 - val_acc: 0.9827\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0074 - acc: 0.9979 - val_loss: 0.1051 - val_acc: 0.9839\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.1082 - val_acc: 0.9838\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.1105 - val_acc: 0.9824\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.1136 - val_acc: 0.9832\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.1351 - val_acc: 0.9822\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.1230 - val_acc: 0.9837\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0046 - acc: 0.9989 - val_loss: 0.1265 - val_acc: 0.9840\n",
            "Test loss: 0.12649620679515766\n",
            "Test accuracy: 0.984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39V1aMguzM5_",
        "colab_type": "text"
      },
      "source": [
        "**RMSprop**\n",
        "\n",
        "Test loss: 0.12649620679515766\n",
        "\n",
        "\n",
        "Test accuracy: 0.984"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqC0OdUMyDvV",
        "colab_type": "code",
        "outputId": "4a23f4ce-36ce-463d-f924-f7527ac76174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0327 - acc: 0.9956 - val_loss: 0.1169 - val_acc: 0.9834\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 8.0639e-04 - acc: 0.9998 - val_loss: 0.1113 - val_acc: 0.9839\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 3.3472e-04 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9847\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.8906e-04 - acc: 1.0000 - val_loss: 0.1088 - val_acc: 0.9849\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.8555e-04 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 0.9849\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.8349e-04 - acc: 1.0000 - val_loss: 0.1084 - val_acc: 0.9849\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.8201e-04 - acc: 1.0000 - val_loss: 0.1083 - val_acc: 0.9849\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.8091e-04 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9849\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.8001e-04 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 0.9848\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.7928e-04 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9848\n",
            "Test loss: 0.10811926535155592\n",
            "Test accuracy: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ytjhMMtz2Gw",
        "colab_type": "text"
      },
      "source": [
        "**Adagard**\n",
        "\n",
        "Test loss: 0.10811926535155592\n",
        "\n",
        "\n",
        "Test accuracy: 0.9848"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byDFsBzDyaOs",
        "colab_type": "code",
        "outputId": "0b7cac94-81bc-4ac8-887e-4552a482abf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 2.7868e-04 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9849\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 2.7713e-04 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9849\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 2.7614e-04 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 0.9849\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 2.7542e-04 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9849\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.7486e-04 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9848\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 2.7440e-04 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9848\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.7402e-04 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9849\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 2.7370e-04 - acc: 1.0000 - val_loss: 0.1080 - val_acc: 0.9850\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 2.7343e-04 - acc: 1.0000 - val_loss: 0.1080 - val_acc: 0.9850\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 2.7319e-04 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9850\n",
            "Test loss: 0.10811314213337339\n",
            "Test accuracy: 0.985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKZtI_O6z8rN",
        "colab_type": "text"
      },
      "source": [
        "**Adadelta**\n",
        "\n",
        "Test loss: 0.10811314213337339\n",
        "\n",
        "\n",
        "Test accuracy: 0.985"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfoDsuqIyffM",
        "colab_type": "code",
        "outputId": "2d51f370-9255-45cf-f43c-92a57c9adef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.0205 - acc: 0.9948 - val_loss: 0.1604 - val_acc: 0.9785\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0134 - acc: 0.9966 - val_loss: 0.1151 - val_acc: 0.9812\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.1127 - val_acc: 0.9804\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0134 - acc: 0.9962 - val_loss: 0.1156 - val_acc: 0.9799\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0098 - acc: 0.9971 - val_loss: 0.1237 - val_acc: 0.9804\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0075 - acc: 0.9979 - val_loss: 0.1263 - val_acc: 0.9791\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0121 - acc: 0.9967 - val_loss: 0.1117 - val_acc: 0.9814\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.1426 - val_acc: 0.9779\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0127 - acc: 0.9966 - val_loss: 0.1240 - val_acc: 0.9803\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0090 - acc: 0.9974 - val_loss: 0.1125 - val_acc: 0.9806\n",
            "Test loss: 0.11245599556569041\n",
            "Test accuracy: 0.9806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRQClsAd0Eet",
        "colab_type": "text"
      },
      "source": [
        "**Adam**\n",
        "\n",
        "Test loss: 0.11245599556569041\n",
        "\n",
        "\n",
        "Test accuracy: 0.9806"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NtYY-P3ylvs",
        "colab_type": "code",
        "outputId": "ed11fe0d-b678-4e16-ce22-3ead14a9a320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.1103 - val_acc: 0.9842\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 3.2995e-04 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 0.9848\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.9747e-04 - acc: 1.0000 - val_loss: 0.1110 - val_acc: 0.9847\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.8722e-04 - acc: 1.0000 - val_loss: 0.1120 - val_acc: 0.9845\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.8111e-04 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9842\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.7675e-04 - acc: 1.0000 - val_loss: 0.1135 - val_acc: 0.9840\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.7411e-04 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9844\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.7210e-04 - acc: 1.0000 - val_loss: 0.1156 - val_acc: 0.9845\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 2.7100e-04 - acc: 1.0000 - val_loss: 0.1163 - val_acc: 0.9849\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7012e-04 - acc: 1.0000 - val_loss: 0.1183 - val_acc: 0.9851\n",
            "Test loss: 0.11826916954151595\n",
            "Test accuracy: 0.9851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 188.00 264.00\" width=\"251pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 184,-260 184,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140633988019312 -->\n<g class=\"node\" id=\"node1\">\n<title>140633988019312</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 180,-255.5 180,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-233.8\">dense_30_input: InputLayer</text>\n</g>\n<!-- 140633988399680 -->\n<g class=\"node\" id=\"node2\">\n<title>140633988399680</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 147,-182.5 147,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-160.8\">dense_30: Dense</text>\n</g>\n<!-- 140633988019312&#45;&gt;140633988399680 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140633988019312-&gt;140633988399680</title>\n<path d=\"M90,-219.4551C90,-211.3828 90,-201.6764 90,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.5001,-192.5903 90,-182.5904 86.5001,-192.5904 93.5001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140633994999232 -->\n<g class=\"node\" id=\"node3\">\n<title>140633994999232</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 147,-109.5 147,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-87.8\">dense_31: Dense</text>\n</g>\n<!-- 140633988399680&#45;&gt;140633994999232 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140633988399680-&gt;140633994999232</title>\n<path d=\"M90,-146.4551C90,-138.3828 90,-128.6764 90,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.5001,-119.5903 90,-109.5904 86.5001,-119.5904 93.5001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140633988019424 -->\n<g class=\"node\" id=\"node4\">\n<title>140633988019424</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 147,-36.5 147,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-14.8\">dense_32: Dense</text>\n</g>\n<!-- 140633994999232&#45;&gt;140633988019424 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140633994999232-&gt;140633988019424</title>\n<path d=\"M90,-73.4551C90,-65.3828 90,-55.6764 90,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"93.5001,-46.5903 90,-36.5904 86.5001,-46.5904 93.5001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXWJYUxK0JBN",
        "colab_type": "text"
      },
      "source": [
        "**Adamax**\n",
        "\n",
        "Test loss: 0.11826916954151595\n",
        "\n",
        "\n",
        "Test accuracy: 0.9851"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN-m8uTByrY0",
        "colab_type": "code",
        "outputId": "9878d2c0-b68a-499f-df96-90652f780919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 0.0213 - acc: 0.9938 - val_loss: 0.1302 - val_acc: 0.9769\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0179 - acc: 0.9947 - val_loss: 0.1131 - val_acc: 0.9813\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0104 - acc: 0.9969 - val_loss: 0.1004 - val_acc: 0.9823\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.1160 - val_acc: 0.9805\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0190 - acc: 0.9945 - val_loss: 0.1098 - val_acc: 0.9809\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0109 - acc: 0.9970 - val_loss: 0.1038 - val_acc: 0.9810\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0137 - acc: 0.9963 - val_loss: 0.1240 - val_acc: 0.9803\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0175 - acc: 0.9955 - val_loss: 0.1382 - val_acc: 0.9797\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0124 - acc: 0.9968 - val_loss: 0.1355 - val_acc: 0.9788\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0109 - acc: 0.9972 - val_loss: 0.1260 - val_acc: 0.9813\n",
            "Test loss: 0.12597350687139072\n",
            "Test accuracy: 0.9813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hog5uwzZ0V1F",
        "colab_type": "text"
      },
      "source": [
        "**Nadam**\n",
        "\n",
        "Test loss: 0.12597350687139072\n",
        "\n",
        "\n",
        "Test accuracy: 0.9813"
      ]
    }
  ]
}